b'<?xml version="1.0" ?>\n<!DOCTYPE PubmedArticleSet PUBLIC "-//NLM//DTD PubMedArticle, 1st January 2019//EN" "https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_190101.dtd">\n<PubmedArticleSet>\n<PubmedArticle>\n    <MedlineCitation Status="Publisher" Owner="NLM">\n        <PMID Version="1">31034414</PMID>\n        <DateRevised>\n            <Year>2019</Year>\n            <Month>11</Month>\n            <Day>20</Day>\n        </DateRevised>\n        <Article PubModel="Print-Electronic">\n            <Journal>\n                <ISSN IssnType="Electronic">1941-0042</ISSN>\n                <JournalIssue CitedMedium="Internet">\n                    <PubDate>\n                        <Year>2019</Year>\n                        <Month>Apr</Month>\n                        <Day>25</Day>\n                    </PubDate>\n                </JournalIssue>\n                <Title>IEEE transactions on image processing : a publication of the IEEE Signal Processing Society</Title>\n                <ISOAbbreviation>IEEE Trans Image Process</ISOAbbreviation>\n            </Journal>\n            <ArticleTitle>Re-ranking High-Dimensional Deep Local Representation for NIR-VIS Face Recognition.</ArticleTitle>\n            <ELocationID EIdType="doi" ValidYN="Y">10.1109/TIP.2019.2912360</ELocationID>\n            <Abstract>\n                <AbstractText>Heterogeneous face recognition refers to matching facial images captured from different sensors or sources, which has wide applications in public security and law enforcement. Because of the great differences in sensing and creating procedure, there are huge feature gap between heterogeneous facial images. Existing methods merely focus on comparing the probe image with the gallery in feature space, while the true target may not appear at the first rank due to the appearance variations caused by different sensing patterns. In order to exploit valuable information from initial ranking result, this paper proposes to re-rank high-dimensional deep local representation for matching near-infrared (NIR) and visual (VIS) facial images, i.e. NIR-VIS face recognition. A high-dimensional deep local representation is firstly constructed by extracting and concatenating deep features on local facial patches via a convolutional neural network (CNN). The initial NIR-VIS recognition ranking results can be obtained by comparing the compressed deep features. We then propose a novel and efficient locally linear re-ranking (LLRe-Rank) technique to refine the initial ranking results, which can explore valuable information from initial ranking result. The proposed re-ranking method does not require any human interaction or data annotation, and can be served as an unsupervised post processing technique. Experimental results on the most challenging Oulu-CASIA NIR-VIS database and CASIA NIR-VIS 2.0 database demonstrate the effectiveness of our method.</AbstractText>\n            </Abstract>\n            <AuthorList CompleteYN="Y">\n                <Author ValidYN="Y">\n                    <LastName>Peng</LastName>\n                    <ForeName>Chunlei</ForeName>\n                    <Initials>C</Initials>\n                </Author>\n                <Author ValidYN="Y">\n                    <LastName>Wang</LastName>\n                    <ForeName>Nannan</ForeName>\n                    <Initials>N</Initials>\n                </Author>\n                <Author ValidYN="Y">\n                    <LastName>Li</LastName>\n                    <ForeName>Jie</ForeName>\n                    <Initials>J</Initials>\n                </Author>\n                <Author ValidYN="Y">\n                    <LastName>Gao</LastName>\n                    <ForeName>Xinbo</ForeName>\n                    <Initials>X</Initials>\n                </Author>\n            </AuthorList>\n            <Language>eng</Language>\n            <PublicationTypeList>\n                <PublicationType UI="D016428">Journal Article</PublicationType>\n            </PublicationTypeList>\n            <ArticleDate DateType="Electronic">\n                <Year>2019</Year>\n                <Month>04</Month>\n                <Day>25</Day>\n            </ArticleDate>\n        </Article>\n        <MedlineJournalInfo>\n            <Country>United States</Country>\n            <MedlineTA>IEEE Trans Image Process</MedlineTA>\n            <NlmUniqueID>9886191</NlmUniqueID>\n            <ISSNLinking>1057-7149</ISSNLinking>\n        </MedlineJournalInfo>\n    </MedlineCitation>\n    <PubmedData>\n        <History>\n            <PubMedPubDate PubStatus="entrez">\n                <Year>2019</Year>\n                <Month>4</Month>\n                <Day>30</Day>\n                <Hour>6</Hour>\n                <Minute>0</Minute>\n            </PubMedPubDate>\n            <PubMedPubDate PubStatus="pubmed">\n                <Year>2019</Year>\n                <Month>4</Month>\n                <Day>30</Day>\n                <Hour>6</Hour>\n                <Minute>0</Minute>\n            </PubMedPubDate>\n            <PubMedPubDate PubStatus="medline">\n                <Year>2019</Year>\n                <Month>4</Month>\n                <Day>30</Day>\n                <Hour>6</Hour>\n                <Minute>0</Minute>\n            </PubMedPubDate>\n        </History>\n        <PublicationStatus>aheadofprint</PublicationStatus>\n        <ArticleIdList>\n            <ArticleId IdType="pubmed">31034414</ArticleId>\n            <ArticleId IdType="doi">10.1109/TIP.2019.2912360</ArticleId>\n        </ArticleIdList>\n    </PubmedData>\n</PubmedArticle>\n\n</PubmedArticleSet>'